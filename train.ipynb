{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train_solved_1.csv')\n",
    "df_test = pd.read_csv('data/test_solved_1.csv')\n",
    "df_label = pd.read_csv('data/label_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据归一化，效果较差\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scale_list = ['Age','DistanceFromHome', 'Education', 'EnvironmentSatisfaction', 'JobInvolvement', 'JobSatisfaction',\n",
    "              'MonthlyIncome', 'NumCompaniesWorked', 'PercentSalaryHike', 'RelationshipSatisfaction', 'StockOptionLevel',\n",
    "         'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsAtCompany', \n",
    "              'YearsWithCurrManager']\n",
    "for item in df_train.columns:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_train[item].values.reshape(-1, 1).astype('float64'))\n",
    "    df_train[item] = scaler.transform(df_train[item].values.reshape(-1, 1).astype('float64'))\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_test[item].values.reshape(-1, 1).astype('float64'))\n",
    "    df_test[item] = scaler.transform(df_test[item].values.reshape(-1, 1).astype('float64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主成分分析，效果一般\n",
    "def pca_data(df):\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components='mle', copy=False,)\n",
    "    df = pca.fit_transform(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对属性值进行one-hot编码，避免某些特征权重过大\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy import sparse\n",
    "\n",
    "feats = [\"Age\",\"BusinessTravel\",\"Department\",\"DistanceFromHome\",\"Education\",\"EducationField\",\n",
    "    \"EnvironmentSatisfaction\",\"Gender\",\"JobInvolvement\",\"JobLevel\",\"JobRole\",\"JobSatisfaction\",\"MaritalStatus\",\"MonthlyIncome\",\n",
    "    \"NumCompaniesWorked\",\"OverTime\",\"PercentSalaryHike\",\"PerformanceRating\",\"RelationshipSatisfaction\",\n",
    "    \"StockOptionLevel\",\"TotalWorkingYears\",\"TrainingTimesLastYear\",\"WorkLifeBalance\",\"YearsAtCompany\",\"YearsInCurrentRole\",\n",
    "    \"YearsSinceLastPromotion\",\"YearsWithCurrManager\",\"AgeDistance\",\"AgeEnvir\",\"JobRoleLevel\",\"OverPerRating\"]\n",
    "for (i, feat) in enumerate(feats):\n",
    "    encoder = OneHotEncoder(categories='auto')\n",
    "    encoder.fit(np.hstack((df_train[feat].values, df_test[feat].values)).reshape(-1, 1))\n",
    "    x_train = encoder.transform(df_train[feat].values.reshape(-1, 1))\n",
    "    x_test = encoder.transform(df_test[feat].values.reshape(-1, 1))\n",
    "    if i == 0:\n",
    "        # 第一个不需要拼合到最终矩阵，因为是起点\n",
    "        X_train = x_train\n",
    "        X_test = x_test\n",
    "    else:\n",
    "        # 后面的拼合到第一矩阵，为稀疏矩阵\n",
    "        X_train = sparse.hstack((X_train, x_train))\n",
    "        X_test = sparse.hstack((X_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train\n",
    "y_train = df_label['label']\n",
    "x_test = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model is LR\n",
      "[0.9009009  0.86486486 0.89090909 0.89090909 0.90909091 0.86363636\n",
      " 0.85454545 0.85454545 0.86238532 0.86238532]\n",
      "Mean accuracy is 0.8754172771603963\n",
      "****************************************************************************************************\n",
      "the model is SVM\n",
      "[0.83783784 0.83783784 0.83636364 0.83636364 0.83636364 0.83636364\n",
      " 0.83636364 0.83636364 0.8440367  0.8440367 ]\n",
      "Mean accuracy is 0.8381930888352906\n",
      "****************************************************************************************************\n",
      "the model is DT\n",
      "[0.85585586 0.83783784 0.82727273 0.83636364 0.83636364 0.83636364\n",
      " 0.85454545 0.84545455 0.78899083 0.80733945]\n",
      "Mean accuracy is 0.8326387605286687\n",
      "****************************************************************************************************\n",
      "the model is RF\n",
      "[0.85585586 0.84684685 0.83636364 0.84545455 0.85454545 0.83636364\n",
      " 0.84545455 0.85454545 0.86238532 0.85321101]\n",
      "Mean accuracy is 0.8491026305705205\n",
      "****************************************************************************************************\n",
      "the model is AdaBoost\n",
      "[0.87387387 0.83783784 0.84545455 0.85454545 0.88181818 0.85454545\n",
      " 0.83636364 0.86363636 0.87155963 0.85321101]\n",
      "Mean accuracy is 0.8572845990277184\n",
      "****************************************************************************************************\n",
      "the model is GBDT\n",
      "[0.87387387 0.82882883 0.83636364 0.84545455 0.88181818 0.82727273\n",
      " 0.83636364 0.86363636 0.87155963 0.8440367 ]\n",
      "Mean accuracy is 0.8509208123887022\n",
      "****************************************************************************************************\n",
      "the model is NN\n",
      "[0.85585586 0.83783784 0.85454545 0.84545455 0.9        0.85454545\n",
      " 0.83636364 0.84545455 0.81651376 0.86238532]\n",
      "Mean accuracy is 0.8508956412626137\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# 多模型交叉验证\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "import sklearn.neural_network as sk_nn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "models = {\n",
    "    'LR': LogisticRegression(solver='liblinear', penalty='l2', C=1),\n",
    "    'SVM': SVC(C=1, gamma='auto'),\n",
    "    'DT': DecisionTreeClassifier(),\n",
    "    'RF' : RandomForestClassifier(n_estimators=100),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100),\n",
    "    'GBDT': GradientBoostingClassifier(n_estimators=100),\n",
    "    'NN': sk_nn.MLPClassifier(activation='relu',solver='adam',alpha=0.0001,learning_rate='adaptive',learning_rate_init=0.001, max_iter=1000)  \n",
    "}\n",
    "\n",
    "for k, clf in models.items():\n",
    "    print(\"the model is {}\".format(k))\n",
    "    scores = cross_val_score(clf, x_train, y_train, cv=10)\n",
    "    print(scores)\n",
    "    print(\"Mean accuracy is {}\".format(np.mean(scores)))\n",
    "    print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可以看到，就不调参情况而言，首选的逻辑回归具有较好的准确率，接下来对逻辑回归进行调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.860909090909091\n",
      "{'C': 1.0, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "# 网格搜索调参\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "penaltys = ['l1', 'l2']\n",
    "Cs = np.arange(1, 10, 0.1)\n",
    "parameters = dict(penalty=penaltys, C=Cs )\n",
    "lr_penalty= LogisticRegression(solver='liblinear')\n",
    "grid= GridSearchCV(lr_penalty, parameters,cv=10)\n",
    "grid.fit(x_train,y_train)\n",
    "grid.cv_results_\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "[0.9009009  0.86486486 0.89090909 0.89090909 0.90909091 0.86363636\n",
      " 0.85454545 0.85454545 0.86238532 0.86238532]\n",
      "Mean accuracy is 0.8754172771603963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16957\\Anaconda3\\envs\\DataMining\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "print(clf)\n",
    "scores = cross_val_score(clf, x_train, y_train, cv=10)\n",
    "print(scores)\n",
    "print(\"Mean accuracy is {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train, y_train)\n",
    "result = clf.predict(x_test)\n",
    "file = pd.DataFrame()\n",
    "file['result'] = result\n",
    "file.to_csv('data/result.csv', index=False, encoding='utf-8',)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
